{
  "metadata": {
    "source_document": "DIT869.pdf",
    "course_code": "DIT869",
    "course_title": "Deep machine learning",
    "swedish_title": "Djup maskininlärning",
    "department": "Department of Computer Science and Engineering",
    "field_of_education": "Science 100%",
    "credits": "7.5",
    "cycle": "Second Cycle",
    "main_field_of_study": "Data Science, Computer Science",
    "specialization": "A1F, Second cycle, has second-cycle course/s as entry requirements",
    "language_of_instruction": "English",
    "confirmation_date": "2019-02-08",
    "valid_from_date": "2020-08-31",
    "programmes": [
      "Computer Science, Master's Programme (N2COS)",
      "Applied Data Science Master's Programme (N2ADS)"
    ]
  },
  "sections": {
    "Confirmation": "This course syllabus was confirmed by Department of Computer Science and\nEngineering on 2019-02-08 and was last revised on 2019-12-04 to be valid from 2020-08-\n31, autumn semester of 2020.",
    "Position in the educational system": "The course is offered within several programmes.\nThe course can be part of the following programmes: 1) Computer Science, Master's\nProgramme (N2COS) and 2) Applied Data Science Master's Programme (N2ADS)\nMain field of studies\nData Science\nComputer Science\nSpecialization\nA1F, Second cycle, has second-cycle\ncourse/s as entry requirements\nA1F, Second cycle, has second-cycle\ncourse/s as entry requirements",
    "Entry requirements": "To be eligible to the course, the student must have a Bachelor's degree.\nIn particular, the student must have acquired the following knowledge:\n• 15 credits of courses in programming or equivalent,\n• a course including probability and statistics, such as DIT862 Statistical Methods for\nData Science or MSG810 Mathematical Statistics and Discrete mathematics,\n• 5 credits of linear algebra or equivalent\n• 5 credits of calculus or equivalent,\n• a first course in machine learning, such as DIT866 Applied Machine Learning,\nDIT381 Algorithms for Machine Learning and Inference, or MSA220 Statistical\nLearning for Big Data\nApplicants must prove knowledge of English: English 6/English B or the equivalent level\nof an internationally recognized test, for example TOEFL, IELTS.",
    "Learning outcomes": "On successful completion of the course the student will be able to:\nKnowledge and understanding\n• explain the fundamental principles of supervised (and unsupervised) learning,\nincluding basic techniques like cross-validation to avoid overfitting\n• describe the standard cost functions optimised during supervised training (in\nparticular the cross entropy) and the standard solution techniques (stochastic\ngradient descent, back propagation, etc.)\n• explain how traditional feed-forward networks are constructed and why they can\napproximate \"almost\" any function (the universality theorem)\n• understand the problem with vanishing gradients and modern tools to mitigate it\n(e.g., batch normalisation and residual networks)\n• summarise the key components in convolutional neural networks (CNNs) and their\nkey advantages\n• describe common types of recurrent neural networks (RNN) and their applications\n• provide an overview of some of the many modern variations of the deep learning\nnetworks\n• explain what a Markov decision problem and reinforcement learning (RL) are\nCompetence and skills\n• make use of deep learning to solve RL using, e.g., deep q-learning\n• train and apply CNNs to image applications and RNNs to applications related to\ntime sequences such as those involved in R\n• use a suitable deep learning library (e.g., TensorFlow or Torch) to solve a variety of\npractical applications\nJudgement and approach\n• argue for the benefits and limitations of generative models, transfer learning and\ndata augmentation in situations when we have a limited amount of\nannotated/labelled data",
    "Course content": "The purpose with this course is to give a thorough introduction to deep machine\nlearning, also known as deep learning or deep neural networks. Over the last few years,\ndeep machine learning has dramatically changed the state of the art performance in\nvarious fields including speech-recognition, computer vision and reinforcement learning\n(used, e.g., to learn how to play Go). We focus primarily on basic principles regarding\nhow these networks are constructed and trained, but we also cover many of the key\ntechniques used in different applications. The overall objective is to provide a solid\nunderstanding of how and why deep machine learning is useful, as well as the skills to\napply them to solve problems of practical importance.\nIn the course, the following broad areas will be covered:\n• supervised learning by cross-entropy minimisation and cross-validation\n• back propagation and stochastic gradient descent\n• a suitable programming language for implementing deep learning algorithm\n• feedforward neural networks and convolutional neural networks\n• recurrent neural networks and long short-term memory networks\n• techniques for efficient training such as momentum and batch normalisation\n• modern variations of neural networks (e.g., attention and residual networks)\n• transfer learning and data augmentation\n• reinforcement learning, Markov decision problems, q-learning and deep q-learning\n• application of convolutional neural networks on image recognition and\nreinforcement learning",
    "Sub-courses": "",
    "Form of teaching": "The course comprises on-line lectures (to watch before the class), active learning sessions\n(where we review material from the corresponding lecture), computer exercise sessions,\nconsultation sessions, assignments, a project and tutorial sessions (primarily related to\nthe home assignments).",
    "Assessment": "The course is examined by attendance at compulsory activities, by written assignments\nand a project, out of which some are carried out individually and some in groups of\nnormally 2-4 students. Non-attendance at a limited number of compulsory activities can\nbe tolerated, and will typically be examined through supplementary assignments.\nIf a student, who has failed the same examined component twice, wishes to change\nexaminer before the next examination, a written application shall be sent to the\ndepartment responsible for the course and shall be granted unless there are special\nreasons to the contrary (Chapter 6, Section 22 of Higher Education Ordinance).\nIn cases where a course has been discontinued or has undergone major changes, the\nstudent shall normally be guaranteed at least three examination occasions (including the\nordinary examination) during a period of at least one year from the last time the course\nwas given.",
    "Grades": "The grading scale comprises: Pass with Distinction (VG), Pass (G) and Fail (U).\nTo pass the course, the student needs to attend a sufficient number of compulsory\nactivities, and have the project and all assignments passed. The final grade is based on\nthe performance of the student in the project and the assignments.",
    "Course evaluation": "The course is evaluated through meeting after the course between teachers and student\nrepresentatives. Further, an anonymous questionnaire is used to ensure written\ninformation. The outcome of the evaluations serves to improve the course by indicating\nwhich parts could be added, improved, changed or removed.",
    "Additional information": "The course is a joint course together with Chalmers.\nCourse literature to be announced the latest 8 weeks prior to the start of the course.\nThe course replaces the course DIT868, 7.5 hec. The course cannot be included in a\ndegree which contains DIT868. Neither can the course be included in a degree which is\nbased on another degree in which the course DIT868 is included."
  }
}